#!/usr/bin/env python3
"""
VerificaciÃ³n Final Completa - v5.5.1

Ejecuta una verificaciÃ³n exhaustiva de todas las correcciones aplicadas:
1. Verifica sintaxis corregida
2. Prueba import y funcionalidad bÃ¡sica
3. Analiza ER medido vs teÃ³rico
4. Ejecuta tests automÃ¡ticos
5. Genera reporte final con mÃ©tricas
"""

import os
import sys
import subprocess
import time
import traceback
from pathlib import Path

def print_header():
    """Header del script."""
    print("ğŸ” VERIFICACIÃ“N FINAL COMPLETA v5.5.1")
    print("=" * 65)
    print("Verificando todas las correcciones aplicadas:")
    print("  âœ… Sintaxis del test corregida")
    print("  ğŸ“Š ER mejorado (>4 dB mÃ­nimo)")
    print("  ğŸ”§ Ecuaciones fÃ­sicas funcionando")
    print("  ğŸ§ª Tests pasando")
    print()

def verify_syntax_fixed():
    """Verificar que el error de sintaxis estÃ© corregido."""
    print("ğŸ” VERIFICACIÃ“N 1: SINTAXIS CORREGIDA")
    print("-" * 50)
    
    try:
        result = subprocess.run([
            sys.executable, '-m', 'py_compile', 'tests/test_microring.py'
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("   âœ… Sintaxis de test_microring.py correcta")
            return True
        else:
            print("   âŒ Error de sintaxis persistente:")
            print(f"      {result.stderr}")
            return False
    except Exception as e:
        print(f"   âŒ Error verificando sintaxis: {e}")
        return False

def verify_import_and_basic_functionality():
    """Verificar import y funcionalidad bÃ¡sica."""
    print("\nğŸ” VERIFICACIÃ“N 2: IMPORT Y FUNCIONALIDAD BÃSICA")
    print("-" * 50)
    
    try:
        # Agregar path
        sys.path.insert(0, '.')
        
        # Import bÃ¡sico
        import torch
        from torchonn.layers.microring import MicroringResonator
        print("   âœ… Imports exitosos")
        
        # Crear microring
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        mrr = MicroringResonator(
            radius=10e-6,
            q_factor=5000,
            center_wavelength=1550e-9,
            coupling_mode="critical",
            device=device
        )
        print("   âœ… Microring creado exitosamente")
        
        # Verificar parÃ¡metros
        print(f"      Î± = {mrr.alpha:.6f}")
        print(f"      Îº_critical = {mrr.kappa_critical:.6f}")
        print(f"      ER teÃ³rico = {mrr.extinction_ratio_theory_db:.1f} dB")
        
        return True, mrr, device
        
    except Exception as e:
        print(f"   âŒ Error en import/funcionalidad bÃ¡sica: {e}")
        traceback.print_exc()
        return False, None, None

def analyze_er_performance(mrr, device):
    """Analizar performance del extinction ratio."""
    print("\nğŸ” VERIFICACIÃ“N 3: ANÃLISIS DE ER DETALLADO")
    print("-" * 50)
    
    try:
        import torch
        
        # Test con mÃºltiples resoluciones para robustez
        test_cases = [
            ("Quick test", 500),
            ("Standard test", 1500),
            ("High resolution", 3000)
        ]
        
        results = {}
        
        for test_name, n_points in test_cases:
            print(f"   ğŸ“Š {test_name} ({n_points} puntos):")
            
            wavelengths = mrr.get_recommended_wavelengths(n_points)
            input_signal = torch.ones(1, n_points, device=device, dtype=torch.float32)
            
            with torch.no_grad():
                output = mrr(input_signal, wavelengths)
            
            through_response = output['through'][0]
            drop_response = output['drop'][0]
            
            # AnÃ¡lisis detallado
            min_through = torch.min(through_response)
            max_through = torch.max(through_response)
            max_drop = torch.max(drop_response)
            
            # ER calculation robusto
            if min_through > 1e-15:
                # MÃ©todo 1: Simple max/min
                er_simple = max_through / min_through
                er_simple_db = 10 * torch.log10(er_simple)
                
                # MÃ©todo 2: Off-resonance robusto
                n_edge = max(n_points // 10, 10)
                sorted_vals, _ = torch.sort(through_response, descending=True)
                off_res_max = torch.mean(sorted_vals[:n_edge])
                er_robust = off_res_max / min_through
                er_robust_db = 10 * torch.log10(er_robust)
                
                # ConservaciÃ³n de energÃ­a
                total_energy = through_response + drop_response
                max_energy = torch.max(total_energy)
                
                results[test_name] = {
                    'min_through': min_through.item(),
                    'max_through': max_through.item(),
                    'er_simple_db': er_simple_db.item(),
                    'er_robust_db': er_robust_db.item(),
                    'max_energy': max_energy.item(),
                    'n_points': n_points
                }
                
                print(f"      Through: min={min_through:.6f}, max={max_through:.6f}")
                print(f"      ER simple: {er_simple_db:.1f} dB")
                print(f"      ER robusto: {er_robust_db:.1f} dB")
                print(f"      ConservaciÃ³n: {max_energy:.3f}")
                
            else:
                print(f"      âŒ Through min demasiado bajo: {min_through:.2e}")
                results[test_name] = None
        
        # AnÃ¡lisis de consistencia
        valid_results = {k: v for k, v in results.items() if v is not None}
        
        if len(valid_results) >= 2:
            ers = [r['er_robust_db'] for r in valid_results.values()]
            er_std = torch.std(torch.tensor(ers)).item()
            er_mean = torch.mean(torch.tensor(ers)).item()
            
            print(f"   ğŸ“Š CONSISTENCIA:")
            print(f"      ER promedio: {er_mean:.1f} dB")
            print(f"      ER std: {er_std:.2f} dB")
            print(f"      ER teÃ³rico: {mrr.extinction_ratio_theory_db:.1f} dB")
            
            # Criterios de Ã©xito
            success_criteria = [
                er_mean > 4,  # ER mÃ­nimo aceptable
                er_std < 2,   # Consistencia entre mediciones
                all(r['max_energy'] < 1.05 for r in valid_results.values())  # ConservaciÃ³n
            ]
            
            success = all(success_criteria)
            
            print(f"   ğŸ¯ EVALUACIÃ“N:")
            print(f"      ER > 4 dB: {'âœ…' if er_mean > 4 else 'âŒ'} ({er_mean:.1f} dB)")
            print(f"      Consistencia: {'âœ…' if er_std < 2 else 'âŒ'} (std={er_std:.2f})")
            print(f"      ConservaciÃ³n: {'âœ…' if all(r['max_energy'] < 1.05 for r in valid_results.values()) else 'âŒ'}")
            
            return success, results
        else:
            print("   âŒ Insuficientes resultados vÃ¡lidos")
            return False, results
            
    except Exception as e:
        print(f"   âŒ Error en anÃ¡lisis de ER: {e}")
        traceback.print_exc()
        return False, {}

def run_automated_tests():
    """Ejecutar tests automÃ¡ticos."""
    print("\nğŸ” VERIFICACIÃ“N 4: TESTS AUTOMÃTICOS")
    print("-" * 50)
    
    tests_to_run = [
        {
            "name": "Test especÃ­fico ER",
            "cmd": [
                sys.executable, "-m", "pytest", 
                "tests/test_microring.py::TestMicroringResonator::test_extinction_ratio_realistic",
                "-v", "--tb=short"
            ],
            "timeout": 60,
            "critical": True
        },
        {
            "name": "Test conservaciÃ³n energÃ­a",
            "cmd": [
                sys.executable, "-m", "pytest", 
                "tests/test_microring.py::TestMicroringResonator::test_energy_conservation",
                "-v", "--tb=short"
            ],
            "timeout": 30,
            "critical": True
        },
        {
            "name": "Test inicializaciÃ³n", 
            "cmd": [
                sys.executable, "-m", "pytest", 
                "tests/test_microring.py::TestMicroringResonator::test_microring_initialization",
                "-v", "--tb=short"
            ],
            "timeout": 30,
            "critical": False
        }
    ]
    
    results = {}
    
    for test in tests_to_run:
        print(f"   ğŸ§ª {test['name']}...")
        
        try:
            result = subprocess.run(
                test['cmd'],
                capture_output=True,
                text=True,
                timeout=test['timeout']
            )
            
            success = result.returncode == 0
            results[test['name']] = {
                'success': success,
                'critical': test['critical'],
                'stdout': result.stdout,
                'stderr': result.stderr
            }
            
            if success:
                print(f"      âœ… PASÃ“")
            else:
                print(f"      âŒ FALLÃ“")
                if test['critical']:
                    print("         ğŸ”´ TEST CRÃTICO")
                
                # Mostrar error relevante
                error_lines = (result.stdout + "\\n" + result.stderr).split('\\n')
                relevant = [l for l in error_lines if any(word in l.lower() for word in ['failed', 'error', 'assert', 'exception'])]
                for line in relevant[-3:]:
                    if line.strip():
                        print(f"         {line[:80]}")
        
        except subprocess.TimeoutExpired:
            print(f"      â±ï¸ TIMEOUT")
            results[test['name']] = {'success': False, 'critical': test['critical'], 'timeout': True}
        except Exception as e:
            print(f"      âŒ ERROR: {e}")
            results[test['name']] = {'success': False, 'critical': test['critical'], 'error': str(e)}
    
    return results

def generate_final_report(syntax_ok, basic_ok, er_analysis_ok, er_results, test_results):
    """Generar reporte final completo."""
    print("\n" + "="*65)
    print("ğŸ“‹ REPORTE FINAL COMPLETO v5.5.1")
    print("="*65)
    
    # Resumen de verificaciones
    print("ğŸ“Š RESUMEN DE VERIFICACIONES:")
    print(f"   1. Sintaxis corregida: {'âœ…' if syntax_ok else 'âŒ'}")
    print(f"   2. Funcionalidad bÃ¡sica: {'âœ…' if basic_ok else 'âŒ'}")
    print(f"   3. AnÃ¡lisis de ER: {'âœ…' if er_analysis_ok else 'âŒ'}")
    
    # Tests automÃ¡ticos
    if test_results:
        passed_tests = sum(1 for r in test_results.values() if r.get('success', False))
        total_tests = len(test_results)
        critical_tests = [k for k, v in test_results.items() if v.get('critical', False)]
        critical_passed = sum(1 for k in critical_tests if test_results[k].get('success', False))
        
        print(f"   4. Tests automÃ¡ticos: {passed_tests}/{total_tests} pasaron")
        print(f"      Tests crÃ­ticos: {critical_passed}/{len(critical_tests)} pasaron")
    
    # MÃ©tricas de ER
    if er_results:
        valid_ers = [r for r in er_results.values() if r is not None]
        if valid_ers:
            avg_er = sum(r['er_robust_db'] for r in valid_ers) / len(valid_ers)
            min_through_avg = sum(r['min_through'] for r in valid_ers) / len(valid_ers)
            print(f"\\nğŸ“Š MÃ‰TRICAS DE EXTINCTION RATIO:")
            print(f"   ER promedio medido: {avg_er:.1f} dB")
            print(f"   Through min promedio: {min_through_avg:.6f}")
            print(f"   Mejora vs inicial: {avg_er:.1f} dB vs ~5.1 dB anterior")
    
    # EvaluaciÃ³n general
    critical_passed_all = all(test_results.get(k, {}).get('success', False) for k in critical_tests) if test_results else False
    
    overall_success = syntax_ok and basic_ok and er_analysis_ok and critical_passed_all
    
    print(f"\\nğŸ¯ EVALUACIÃ“N FINAL:")
    if overall_success:
        print("ğŸ‰ Â¡TODAS LAS CORRECCIONES EXITOSAS!")
        print("   âœ… Error de sintaxis resuelto")
        print("   âœ… Extinction ratio mejorado significativamente")
        print("   âœ… Ecuaciones fÃ­sicas funcionando correctamente")
        print("   âœ… Tests crÃ­ticos pasando")
        print("   âœ… ConservaciÃ³n de energÃ­a garantizada")
        
        print("\\nğŸ“‹ RECOMENDACIONES FINALES:")
        print("   1. âœ… Ejecutar suite completa: pytest tests/test_microring.py -v")
        print("   2. âœ… Verificar otros tests: pytest tests/ -x")
        print("   3. âœ… Commit de las correcciones aplicadas")
        print("   4. âœ… Documentar mejoras en changelog")
        
    else:
        print("âš ï¸ CORRECCIONES PARCIALES - REVISAR PENDIENTES")
        
        if not syntax_ok:
            print("   ğŸ”§ Corregir sintaxis restante manualmente")
        if not basic_ok:
            print("   ğŸ”§ Revisar imports y configuraciÃ³n del proyecto")
        if not er_analysis_ok:
            print("   ğŸ“Š Ajustar parÃ¡metros fÃ­sicos o tolerancias")
        if not critical_passed_all:
            print("   ğŸ§ª Revisar y corregir tests crÃ­ticos")
        
        print("\\nğŸ“‹ ACCIONES RECOMENDADAS:")
        print("   1. Revisar logs de error especÃ­ficos arriba")
        print("   2. Ejecutar diagnÃ³stico detallado")
        print("   3. Considerar restaurar backup si es necesario")
    
    # InformaciÃ³n de archivos
    print(f"\\nğŸ“ ARCHIVOS MODIFICADOS:")
    modified_files = [
        'torchonn/layers/microring.py',
        'tests/test_microring.py'
    ]
    
    for file_path in modified_files:
        if os.path.exists(file_path):
            mod_time = os.path.getmtime(file_path)
            mod_time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(mod_time))
            print(f"   âœ… {file_path} (modificado: {mod_time_str})")
        else:
            print(f"   âŒ {file_path} (faltante)")
    
    # Backups disponibles
    backup_files = [f for f in os.listdir('.') if 'backup' in f and ('microring' in f or 'test_microring' in f)]
    if backup_files:
        print(f"\\nğŸ“ BACKUPS DISPONIBLES ({len(backup_files)}):")
        for backup in sorted(backup_files)[-5:]:  # Ãšltimos 5
            print(f"   ğŸ“„ {backup}")
    
    return overall_success

def main():
    """FunciÃ³n principal."""
    print_header()
    
    # VerificaciÃ³n 1: Sintaxis
    syntax_ok = verify_syntax_fixed()
    
    # VerificaciÃ³n 2: Funcionalidad bÃ¡sica
    basic_ok, mrr, device = verify_import_and_basic_functionality()
    
    # VerificaciÃ³n 3: AnÃ¡lisis de ER
    er_analysis_ok = False
    er_results = {}
    if basic_ok and mrr is not None:
        er_analysis_ok, er_results = analyze_er_performance(mrr, device)
    
    # VerificaciÃ³n 4: Tests automÃ¡ticos
    test_results = run_automated_tests()
    
    # Reporte final
    success = generate_final_report(syntax_ok, basic_ok, er_analysis_ok, er_results, test_results)
    
    return 0 if success else 1

if __name__ == "__main__":
    exit(main())